import os
import streamlit as st

from langchain_core.messages.chat import ChatMessage

from dotenv import load_dotenv
from langchain_teddynote import logging
from layout_parser import graph_document_ai, GraphState


from constants import PROGRESS_MESSAGE_GRAPH_NODES
from output import clean_cache_files
from document_utils import download_files, check_file_type


# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.
logging.langsmith("Document AI")

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")

# íŒŒì¼ ì—…ë¡œë“œ ì „ìš© í´ë”
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

# ì„ë² ë”© íŒŒì¼ ì €ì¥ í´ë”
if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")


st.title("Document AI ğŸ’¬")

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["document_messages"] = []

if "chain" not in st.session_state:
    # ì•„ë¬´ëŸ° íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ì§€ ì•Šì„ ê²½ìš°
    st.session_state["chain"] = None

if "filepath" not in st.session_state:
    st.session_state["filepath"] = None


# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "Upload a file",
        type=["pdf", "png", "jpg", "jpeg", "bmp", "tiff"],
        accept_multiple_files=True,
    )
    # ëª¨ë¸ ì„ íƒ ë©”ë‰´
    translate_lang = st.selectbox("Translate", ["Korean", "English", "German"], index=0)
    # Translate í† ê¸€ ì¶”ê°€
    translate_toggle = st.checkbox("Enable Translation", value=False)
    # AI Translate & Summary ë²„íŠ¼ ìƒì„±
    start_btn = st.button("Document AI")


# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["document_messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë©”ì‹œë¦¬ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["document_messages"].append(
        ChatMessage(role=role, content=message)
    )


# íŒŒì¼ì„ ìºì‹œ ì €ì¥(ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ì²˜ë¦¬í•  ì˜ˆì •)
def cache_file(files):
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_extension = check_file_type(files[0].name)

    # ì—…ë¡œë“œí•œ íŒŒì¼ì„ ìºì‹œ ë””ë™í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    file_paths = []

    if file_extension == "pdf":
        if len(files) > 1:  # íŒŒì¼ì´ 1ê°œ ì´ìƒì¸ ê²½ìš°
            st.warning("PDF file only support one file")
            st.session_state["filepath"] = None
        else:
            file_content = files[0].read()  # ì²« ë²ˆì§¸ íŒŒì¼ ì½ê¸°
            file_path = f"./.cache/files/{files[0].name}"
            with open(file_path, "wb") as f:
                f.write(file_content)
            # ì¶”ê°€ì ì¸ PDF íŒŒì¼ ì²˜ë¦¬ ì½”ë“œ ì‘ì„± ê°€ëŠ¥
            file_paths.append(file_path)
            st.session_state["filepath"] = file_paths
    elif file_extension == "image":
        for file in files:
            file_content = file.read()  # íŒŒì¼ ì½ê¸°
            file_path = f"./.cache/files/{file.name}"
            with open(file_path, "wb") as f:
                f.write(file_content)
            file_paths.append(file_path)
        st.session_state["filepath"] = file_paths
    else:
        st.warning("Not supported file type")
        st.session_state["filepath"] = None


if uploaded_files:
    # íŒŒì¼ ì—…ë¡œë“œ í›„ retriever ìƒì„± (ì‘ì—…ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ì˜ˆì •)
    cache_file(uploaded_files)
    uploaded_files = None


def process_graph(file_paths):
    # ì§„í–‰ë„ í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
    progress_bar = st.progress(0)
    status_container = st.empty()

    state = GraphState()

    filetype = check_file_type(file_paths[0])
    if filetype == "pdf":
        file_paths = file_paths[0]
    elif filetype == "image":
        file_paths = file_paths
    else:
        st.error("Not supported file type")
        return

    # ê·¸ë˜í”„ ìƒì„±
    message_dict = PROGRESS_MESSAGE_GRAPH_NODES
    graph = graph_document_ai(translate_toggle)
    inputs = {
        "filepath": file_paths,
        "filetype": filetype,
        "batch_size": 10,
        "translate_lang": translate_lang,
        "translate_toggle": translate_toggle,
    }

    total_nodes = len(graph.nodes)

    for i, output in enumerate(graph.stream(inputs)):
        print(f"output: {output}")
        progress = (i + 1) / total_nodes
        progress_bar.progress(progress)

        # ì§„í–‰ë„ë¥¼ ë°±ë¶„ìœ¨ë¡œ ê³„ì‚°
        progress_percentage = int(progress * 100)

        for key, value in output.items():
            # ë‹¤ìŒ ë‹¨ê³„ì˜ ë©”ì‹œì§€ë¥¼ í‘œì‹œ
            status_container.text(f"{progress_percentage}% - {message_dict[key]}")
            state.update(value)

    # Progress barë¥¼ 100%ë¡œ ì„¤ì •í•˜ê³  "Finished!" ë©”ì‹œì§€ë¥¼ ë…¹ìƒ‰ìœ¼ë¡œ í‘œì‹œ
    progress_bar.progress(1.0)
    status_container.markdown(":green[100% - Finished!]")

    return state


if start_btn:
    file_paths = st.session_state["filepath"]
    if file_paths is None:
        st.error("Please upload a file first.")
    else:
        state = process_graph(file_paths)
        download_files(file_paths[0], state, translate_toggle)
        st.session_state["filepath"] = None

        clean_cache_files()


# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("Ask your question!")

# ê²½ê³  ë©”ì‹œì§€ë¥¼ ë„ìš°ê¸° ìœ„í•œ ë¹ˆ ì˜ì—­
warning_msg = st.empty()

if user_input:
    # chainì„ ìƒì„±
    chain = st.session_state["chain"]

    if chain is not None:
        # ì‚¬ìš©ìì˜ ì…ë ¥
        st.chat_message("user").write(user_input)
        # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
        response = chain.stream(user_input)
        with st.chat_message("assistant"):
            # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ë¥¼ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
            container = st.empty()

            ai_answer = ""
            for token in response:
                ai_answer += token
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥
        add_message("user", user_input)
        add_message("assistant", ai_answer)
    else:
        warning_msg.error("Please upload a file first.")
