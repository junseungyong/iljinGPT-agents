import os
from dotenv import load_dotenv
from langchain_teddynote import logging

import streamlit as st

from langchain_core.documents import Document
from messages_util import AgentStreamParser, AgentCallbacks

from agent_util import create_agent_with_chat_history

from typing import List, Union

import time  # íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.
logging.langsmith("Local GPT")

st.title("Local GPT ğŸ’¬")

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # # íŒŒì¼ ì—…ë¡œë“œ
    # uploaded_files = st.file_uploader(
    #     "Upload a file",
    #     type=["pdf", "png", "jpg", "jpeg", "bmp", "tiff"],
    #     accept_multiple_files=True,
    # )

    # ëª¨ë¸ ì„ íƒ ë©”ë‰´
    llm_mode = st.radio(
        "Select Mode",
        ["***ChatGPT***", "***Private GPT***"],
        captions=["***GPT-4o-mini***", "***Llama-3.1-8B***"],
    )
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button("New Chat")


if "localGPT_messages" not in st.session_state:
    st.session_state["localGPT_messages"] = []

if "user_input" not in st.session_state:
    st.session_state["user_input"] = ""

if "observation" not in st.session_state:
    st.session_state["observation"] = {}

if "selected_mode" not in st.session_state:
    st.session_state["selected_mode"] = llm_mode

if "localGPT_agent" not in st.session_state:
    st.session_state["localGPT_agent"] = create_agent_with_chat_history(llm_mode)


# ìƒìˆ˜ ì •ì˜
class MessageRole:
    USER = "user"  # ì‚¬ìš©ì ë©”ì‹œì§€ íƒ€ì…
    ASSISTANT = "assistant"  # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ íƒ€ì…


class MessageType:
    """
    ë©”ì‹œì§€ íƒ€ì…ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    SOURCE = "source"  # ì†ŒìŠ¤ ë©”ì‹œì§€
    TEXT = "text"  # í…ìŠ¤íŠ¸ ë©”ì‹œì§€
    RELATED_INFO = "related_info"  # ê´€ë ¨ ì •ë³´ ë©”ì‹œì§€


def tool_callback(tool) -> None:
    """
    ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        tool (dict): ì‹¤í–‰ëœ ë„êµ¬ ì •ë³´
    """
    if tool_name := tool.get("tool"):
        tool_input = tool.get("tool_input", {})
        query = tool_input.get("query")
        if query:
            status_container = st.empty()
            with status_container.status(f"ğŸ” Searching for **{query}**...") as status:
                status.update(state="complete", expanded=False)
                time.sleep(1)
            status_container.empty()


def observation_callback(observation) -> None:
    """
    ê´€ì°° ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        observation (dict): ê´€ì°° ê²°ê³¼
    """
    if "observation" in observation:
        action = observation["action"]
        tool_name = action.tool
        obs = observation["observation"]
        if isinstance(obs, str) and "Error" in obs:
            st.error(obs)
            st.session_state["localGPT_messages"][-1][
                1
            ].clear()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‚­ì œ

        st.session_state["observation"] = {"tool": tool_name, "observation": obs}
        if tool_name == "search_tavily":
            add_message(MessageRole.ASSISTANT, [MessageType.SOURCE, obs])
            print_source_message(obs)
        # elif tool_name == "create_related_info":
        #     add_message(MessageRole.ASSISTANT, [MessageType.RELATED_INFO, obs])
        #     print_related_info(obs)


def result_callback(result: str) -> None:
    """
    ìµœì¢… ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        result (str): ìµœì¢… ê²°ê³¼
    """
    global ai_answer  # ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸

    if not hasattr(result_callback, "ai_answer"):
        result_callback.ai_answer = ""  # ì´ˆê¸°í™”

    result_callback.ai_answer += result
    st.markdown(result_callback.ai_answer)
    add_message(MessageRole.ASSISTANT, [MessageType.TEXT, result_callback.ai_answer])


# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    """
    ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    for role, content_list in st.session_state["localGPT_messages"]:
        if role == MessageRole.USER:
            user = st.chat_message("user")
        elif role == MessageRole.ASSISTANT:
            assistant = st.chat_message("assistant")
        for content in content_list:
            if isinstance(content, list):
                message_type, message_content = content
                if role == MessageRole.USER:
                    user.write(message_content)
                elif role == MessageRole.ASSISTANT:
                    with assistant:
                        if message_type == MessageType.TEXT:
                            st.markdown(message_content)
                        elif message_type == MessageType.SOURCE:
                            print_source_message(message_content)
                        elif message_type == MessageType.RELATED_INFO:
                            print_related_info(message_content)


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role: MessageRole, content: List[Union[MessageType, any]]):
    """
    ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        role (MessageRole): ë©”ì‹œì§€ ì—­í•  (ì‚¬ìš©ì ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸)
        content (List[Union[MessageType, str]]): ë©”ì‹œì§€ ë‚´ìš©
    """
    messages = st.session_state["localGPT_messages"]
    if messages and messages[-1][0] == role:
        messages[-1][1].extend([content])  # ê°™ì€ ì—­í• ì˜ ì—°ì†ëœ ë©”ì‹œì§€ëŠ” í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤
    else:
        messages.append([role, [content]])  # ìƒˆë¡œìš´ ì—­í• ì˜ ë©”ì‹œì§€ëŠ” ìƒˆë¡œ ì¶”ê°€í•©ë‹ˆë‹¤


def print_source_message(observation: List[Document]):
    """
    ì†ŒìŠ¤ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """

    cols = st.columns(4)

    for i in range(3):
        if i < len(observation):
            with cols[i]:
                link_container = st.empty()
                link_container.link_button(
                    label=observation[i].metadata["title"],
                    url=observation[i].metadata["source"],
                    use_container_width=True,
                )

    # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì€ popoverë¡œ ë‚˜ë¨¸ì§€ ë¬¸ì„œë“¤ í‘œì‹œ
    with cols[3]:
        if len(observation) > 3:
            more_container = st.empty()
            with more_container.popover("More Sources"):
                for doc in observation[3:]:
                    doc_container = st.empty()
                    doc_container.link_button(
                        label=doc.metadata["title"],
                        url=doc.metadata["source"],
                        use_container_width=True,
                    )


def print_related_info(related_info: List[str]):
    """
    ê´€ë ¨ ì •ë³´ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜

    Args:
        related_info (List[str]): ì¶œë ¥í•  ê´€ë ¨ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    with st.expander("Related Information"):
        for i, question in enumerate(related_info):
            key = f"related_info_{i}_{hash(question)}"
            if st.button(question, key=key):
                # ì§ì ‘ chat_messageë¥¼ ìƒì„±í•˜ì§€ ì•Šê³  session stateë§Œ ì—…ë°ì´íŠ¸
                st.session_state["user_input"] = question
                st.rerun()


# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["localGPT_messages"] = []


def execute_agent(user_input: str):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸
    """

    localGPT_agent = st.session_state["localGPT_agent"]
    response = localGPT_agent.stream(
        {"input": user_input}, config={"configurable": {"session_id": "localGPT"}}
    )

    parser_callback = AgentCallbacks(
        tool_callback=tool_callback,
        observation_callback=observation_callback,
        result_callback=result_callback,
    )
    agent_stream_parser = AgentStreamParser(parser_callback)

    with st.chat_message("assistant"):

        for step in response:
            agent_stream_parser.process_agent_steps(step)

    if observation := st.session_state["observation"]:
        if observation["tool"] == "create_related_info":
            add_message(
                MessageRole.ASSISTANT,
                [MessageType.RELATED_INFO, observation["observation"]],
            )
            print_related_info(observation["observation"])
    st.session_state["observation"] = {}


# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ìƒˆë¡œìš´ ì…ë ¥ ì²˜ë¦¬ (chat input ë˜ëŠ” related info ë²„íŠ¼ í´ë¦­)
if temp_input := st.chat_input("Ask me anything!"):
    st.session_state["user_input"] = temp_input

if st.session_state["user_input"]:
    user_input = st.session_state["user_input"]
    st.chat_message("user").write(user_input)
    st.session_state["user_input"] = ""  # ì…ë ¥ ì´ˆê¸°í™”

    add_message(MessageRole.USER, [MessageType.TEXT, user_input])

    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    execute_agent(user_input)
